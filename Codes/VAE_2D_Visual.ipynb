{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21168d91",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/UW-ERSL/MaTruss/blob/main/example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37791139-97be-4ddb-8cbf-c7216db7ed0f",
   "metadata": {
    "id": "37791139-97be-4ddb-8cbf-c7216db7ed0f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os, sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from scipy.spatial import ConvexHull\n",
    "from matplotlib.patches import Polygon\n",
    "sys.path.append(os.path.realpath('./src/'))\n",
    "from utilFuncs import to_np, to_torch\n",
    "from materialEncoder import MaterialEncoder\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7891cd4c-dd6a-4906-bd80-f8905a937591",
   "metadata": {
    "id": "7891cd4c-dd6a-4906-bd80-f8905a937591"
   },
   "source": [
    "### Read material properties from the database. The properties are then scaled to facilitate training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32ab3559-d61c-4b0f-ad1b-21b67199d2c2",
   "metadata": {
    "id": "32ab3559-d61c-4b0f-ad1b-21b67199d2c2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luisy\\AppData\\Local\\Temp\\ipykernel_10396\\2671264124.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  trainingData = torch.tensor(normalizedData).float()\n"
     ]
    }
   ],
   "source": [
    "def preprocessData():\n",
    "  #Chooses the database to extract the properties from\n",
    "  df = pd.read_excel('./data/MaterialDatabase_FULL.xlsx')\n",
    "  #Gets name, class and class number of each material\n",
    "  dataIdentifier = {'name': df[df.columns[0]], 'className':df[df.columns[1]], 'classID':df[df.columns[2]]}\n",
    "  #Gets in logarithmic from the values of the properties of each material\n",
    "  trainInfo = np.log10(df[df.columns[3:]].to_numpy())\n",
    "  #Scales the properties and normalize them to train the VAE equally among all properties\n",
    "  dataScaleMax = torch.tensor(np.max(trainInfo, axis = 0))\n",
    "  dataScaleMin = torch.tensor(np.min(trainInfo, axis = 0))\n",
    "  normalizedData = (torch.tensor(trainInfo) - dataScaleMin)/(dataScaleMax - dataScaleMin)\n",
    "  #Gets the normalized values\n",
    "  trainingData = torch.tensor(normalizedData).float()\n",
    "  #Gets an array with the minimum and maximum values of each properties\n",
    "  dataInfo = {'youngsModulus':{'idx':0,'scaleMin':dataScaleMin[0], 'scaleMax':dataScaleMax[0]},\\\n",
    "              'costPerKg':{'idx':1,'scaleMin':dataScaleMin[1], 'scaleMax':dataScaleMax[1]},\\\n",
    "              'massDensity':{'idx':2,'scaleMin':dataScaleMin[2], 'scaleMax':dataScaleMax[2]},\\\n",
    "              'yieldStrength':{'idx':3,'scaleMin':dataScaleMin[3], 'scaleMax':dataScaleMax[3]},\n",
    "              'co2Kg':{'idx':4,'scaleMin':dataScaleMin[4], 'scaleMax':dataScaleMax[4]},\n",
    "              'energyKg':{'idx':5,'scaleMin':dataScaleMin[5], 'scaleMax':dataScaleMax[5]},\n",
    "              'waterKg':{'idx':6,'scaleMin':dataScaleMin[6], 'scaleMax':dataScaleMax[6]}}\n",
    "    \n",
    "  return trainingData, dataInfo, dataIdentifier, trainInfo, df\n",
    "trainingData, dataInfo, dataIdentifier, trainInfo, df = preprocessData()\n",
    "#Gets number of materials and number of properties\n",
    "numMaterialsInTrainingData, numFeatures = trainingData.shape\n",
    "props = df.columns[3:].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d68bdfd-a89f-4d90-9b11-e404b44e7552",
   "metadata": {
    "id": "5d68bdfd-a89f-4d90-9b11-e404b44e7552"
   },
   "source": [
    "### VAE training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ee5a7c-ac8b-4c89-bfdd-d960468f1943",
   "metadata": {
    "id": "89ee5a7c-ac8b-4c89-bfdd-d960468f1943",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0 reconLoss 4.68E+01 klLoss 5.67E-03 loss 4.68E+01\n",
      "Iter 500 reconLoss 2.33E-01 klLoss 6.02E-02 loss 2.93E-01\n",
      "Iter 1000 reconLoss 1.08E-01 klLoss 5.91E-02 loss 1.67E-01\n",
      "Iter 1500 reconLoss 7.33E-02 klLoss 5.82E-02 loss 1.32E-01\n",
      "Iter 2000 reconLoss 6.02E-02 klLoss 5.65E-02 loss 1.17E-01\n",
      "Iter 2500 reconLoss 4.35E-02 klLoss 5.46E-02 loss 9.81E-02\n",
      "Iter 3000 reconLoss 4.59E-02 klLoss 5.28E-02 loss 9.87E-02\n",
      "Iter 3500 reconLoss 3.41E-02 klLoss 5.15E-02 loss 8.56E-02\n",
      "Iter 4000 reconLoss 3.73E-02 klLoss 5.02E-02 loss 8.75E-02\n",
      "Iter 4500 reconLoss 3.03E-02 klLoss 4.89E-02 loss 7.91E-02\n",
      "Iter 5000 reconLoss 2.83E-02 klLoss 4.79E-02 loss 7.62E-02\n",
      "Iter 5500 reconLoss 2.79E-02 klLoss 4.69E-02 loss 7.48E-02\n",
      "Iter 6000 reconLoss 3.14E-02 klLoss 4.57E-02 loss 7.71E-02\n",
      "Iter 6500 reconLoss 2.66E-02 klLoss 4.51E-02 loss 7.17E-02\n"
     ]
    }
   ],
   "source": [
    "#Defines the dimension of the latent space and the number of neurons\n",
    "latentDim, hiddenDim = 2, 250\n",
    "#Defines a maximum of itrations\n",
    "numEpochs = 50000\n",
    "#Defines a klFactor\n",
    "klFactor = 5e-5\n",
    "#Defines a learning rate\n",
    "learningRate = 2e-3\n",
    "#Defines the stopping criteria\n",
    "epsilon=4.1e-2\n",
    "#Sets where to save the vaeNet\n",
    "savedNet = './data/vaeNet.nt'\n",
    "vaeSettings = {'encoder':{'inputDim':numFeatures, 'hiddenDim':hiddenDim,\\\n",
    "                                          'latentDim':latentDim},\\\n",
    "               'decoder':{'latentDim':latentDim, 'hiddenDim':hiddenDim,\\\n",
    "                                          'outputDim':numFeatures}}\n",
    "#Loads the encoder from src\\materialEncoder.py\n",
    "materialEncoder = MaterialEncoder(trainingData, dataInfo, dataIdentifier, vaeSettings)\n",
    "\n",
    "start = time.perf_counter()\n",
    "#Runs the the trainAutoencoder function from src\\materialEncoder.py\n",
    "convgHistory = materialEncoder.trainAutoencoder(numEpochs, klFactor, savedNet, learningRate,epsilon)\n",
    "print('training time : {:.2F}'.format(time.perf_counter() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d9bbc2-03a1-4184-a872-345bb731d94e",
   "metadata": {
    "id": "d6d9bbc2-03a1-4184-a872-345bb731d94e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32507f22",
   "metadata": {},
   "source": [
    "## PLots loss evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12594c0-a2f4-4f8e-a631-fd18c836f862",
   "metadata": {
    "id": "b12594c0-a2f4-4f8e-a631-fd18c836f862"
   },
   "outputs": [],
   "source": [
    "# Moving average convergence plots\n",
    "def plotConvergence(convg):\n",
    "  plt.figure();\n",
    "  strokes = ['--', '-.', '-', ':']\n",
    "  for ctr, key in enumerate(convg):\n",
    "    \n",
    "    y = np.array(convg[key])\n",
    "    y_mvavg = np.convolve(y, np.ones(1), 'valid') / 1.\n",
    "    plt.semilogy(y_mvavg, strokes[ctr], label = str(key))\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel(str(key))\n",
    "    plt.grid('True')\n",
    "    plt.legend()\n",
    "    plt.savefig('./figures2D/convergence.pdf')\n",
    "\n",
    "plotConvergence(convgHistory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c95cd32",
   "metadata": {},
   "source": [
    "## Measure differences between input and output of the trained VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7694cd-ccd4-4d91-98a9-202373df3e11",
   "metadata": {
    "id": "3e7694cd-ccd4-4d91-98a9-202373df3e11"
   },
   "outputs": [],
   "source": [
    "matidxs = np.array([2,11,19,45,53,68,73,4,77]).astype(int)-2\n",
    "#props = ['youngsModulus','costPerKg','massDensity','yieldStrength']\n",
    "print([dataIdentifier['name'][i] for i in matidxs])\n",
    "print('\\t \\t ------TRUE DATA----------')\n",
    "print('material name', end = '\\t')\n",
    "for p in props:\n",
    "    print(p, end = '\\t')\n",
    "for i in matidxs:\n",
    "  print(f\"\\n {dataIdentifier['name'][i]} \\t \", end = '')\n",
    "  for p in props:\n",
    "    idx = materialEncoder.dataInfo[p]['idx']\n",
    "    print('\\t {:.2E}'.format(10.**trainInfo[i,idx]),end='')\n",
    "\n",
    "def unnormalize(val, minval ,maxval):\n",
    "  return 10.**(minval + (maxval-minval)*val)\n",
    "def decodeAll():\n",
    "  vae = materialEncoder.vaeNet\n",
    "  decoded = vae.decoder(vae.encoder.z)\n",
    "  matProp = {'youngsModulus':None,'costPerKg':None,'massDensity':None,'yieldStrength':None}\n",
    "  for k in props:\n",
    "    idx = materialEncoder.dataInfo[k]['idx']\n",
    "    scaleMax = materialEncoder.dataInfo[k]['scaleMax']\n",
    "    scaleMin = materialEncoder.dataInfo[k]['scaleMin']\n",
    "    matProp[k] = unnormalize(decoded[:,idx], scaleMin ,scaleMax)\n",
    "  return matProp\n",
    "\n",
    "matProp = decodeAll()\n",
    "print('\\n \\n \\t \\t ------RECONSTRUCTED DATA----------') \n",
    "print('material name', end = '\\t')\n",
    "for p in props:\n",
    "    print(p, end = '\\t')\n",
    "  \n",
    "for i in matidxs:\n",
    "  print(f\"\\n {dataIdentifier['name'][i]} \\t \", end = '')\n",
    "  for p in props:\n",
    "    print('\\t {:.2E}'.format(matProp[p][i]), end='')\n",
    "\n",
    "\n",
    "merr = -1000000000.\n",
    "maxError = {key: merr for key in props}\n",
    "\n",
    "\n",
    "print('\\n \\n \\t \\t ------RECON ERROR (%)----------') \n",
    "print('material name', end = '\\t')\n",
    "acum_error=np.zeros(len(props))\n",
    "\n",
    "for p in props:\n",
    "    print(p, end = '\\t')\n",
    "for i in range(trainInfo.shape[0]):\n",
    "  if(i in matidxs): #\n",
    "    print(f\"\\n {dataIdentifier['name'][i]} \\t \", end = '')\n",
    "  for p in props:\n",
    "    idx = materialEncoder.dataInfo[p]['idx']\n",
    "    trueData = 10**trainInfo[i,idx]\n",
    "    reconData = matProp[p][i]\n",
    "    err = torch.abs(100.*(trueData - reconData)/trueData)\n",
    "    acum_error[idx]=acum_error[idx]+err\n",
    "    if(err > maxError[p]):\n",
    "      maxError[p] = err\n",
    "    if(i in matidxs):\n",
    "      print('\\t {:.1F}'.format(err), end='')\n",
    "      \n",
    "print('\\n\\033[1;31m max Error \\t \\033[0m', end = '')\n",
    "for p in props:\n",
    "  print('\\033[1;31m \\t {:.1F} \\033[0m'.format(maxError[p]), end='')\n",
    "print('\\n\\033[1;31m avg Error \\t \\033[0m', end='')\n",
    "for p in props:\n",
    "  idx = materialEncoder.dataInfo[p]['idx']\n",
    "  print('\\033[1;31m \\t {:.1F} \\033[0m'.format(acum_error[idx]/trainInfo.shape[0]), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba69cc6",
   "metadata": {},
   "source": [
    "## Measures distance between materials based on their euclidean distance in the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40a8a5c-7d7b-4497-b985-b08bb8c96d98",
   "metadata": {
    "id": "d40a8a5c-7d7b-4497-b985-b08bb8c96d98",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# distance matrix between a select candidate of materials\n",
    "def drawDistanceMatrix():\n",
    "  #List of materials, which are by default 3 steels, 3 aluminiums and 3 plastics\n",
    "  matidxs = np.array([2,11,19,45,53,68,73,4,77]).astype(int)-2 # the rows of mats to consider in the db\n",
    "  distMatrix = np.zeros((len(matidxs),)*2)\n",
    "  sns.set_style(\"dark\")\n",
    "  #Loads the VAE\n",
    "  vae = materialEncoder.vaeNet\n",
    "  #Loads latent space coordinates of the materials\n",
    "  z_np = to_np(vae.encoder.z)\n",
    "  for rw in range(len(matidxs)):\n",
    "    for col in range(rw, len(matidxs)):\n",
    "      mx, my = matidxs[rw], matidxs[col]\n",
    "      #Gets the euclidean norm from the z coordinates\n",
    "      distMatrix[rw,col] = np.linalg.norm(z_np[mx,:] - z_np[my,:])\n",
    "      distMatrix[col,rw] = distMatrix[rw,col]\n",
    "  #Gets the maximum value of distance so that is used to scale the maximum value to 1\n",
    "  maxval = np.max(distMatrix)\n",
    "\n",
    "  distMatrix = distMatrix/maxval\n",
    "\n",
    "  matplotlib.rcParams['figure.figsize'] = (15, 15)\n",
    "  plt.matshow(distMatrix,cmap=\"coolwarm\", alpha = 0.75)\n",
    "\n",
    "  ax = plt.gca()\n",
    "\n",
    "  # Set the plot labels\n",
    "  xlabels = [dataIdentifier['name'][i] for i in matidxs]\n",
    "  ax.set_xticks(range(len(matidxs)))\n",
    "  ax.set_xticklabels(xlabels, rotation = 90, size = 12)\n",
    "  ax.set_yticks(range(len(matidxs)))\n",
    "  ax.set_yticklabels(xlabels, size = 12)\n",
    "  plt.grid(which='minor',c='indigo', ls='-', lw='5.8')\n",
    "  \n",
    "\n",
    "  #Add text to the plot showing the values at that point\n",
    "  for i in range(len(matidxs)):\n",
    "      for j in range(i,len(matidxs)):\n",
    "          pltText = '{:.2F}'.format(distMatrix[i,j])\n",
    "          plt.text(j,i, pltText, horizontalalignment='center', \\\n",
    "                     verticalalignment='center', size = 12)\n",
    "  plt.savefig('./figures2D/distanceMatrix.pdf',bbox_inches='tight', dpi = 200)\n",
    "  plt.show()\n",
    "  \n",
    "\n",
    "  #Now gets an average distance among the 3 materials of each group\n",
    "  avgMatrix = np.zeros((3,3))\n",
    "  for i in range(3):\n",
    "    for j in range(3):\n",
    "      avgMatrix[i,j] = np.mean(distMatrix[3*i:3*(i+1), 3*j:3*(j+1)])\n",
    "  \n",
    "  \n",
    "  \n",
    "  plt.matshow(avgMatrix,cmap=\"coolwarm\", alpha = 0.75)\n",
    "  ax = plt.gca()\n",
    "  for i in range(3):\n",
    "    for j in range(3):\n",
    "        pltText = '{:.2F}'.format(avgMatrix[i,j])\n",
    "        plt.text(j,i, pltText, horizontalalignment='center', \\\n",
    "                   verticalalignment='center', size = 24)\n",
    "  xlabels = ['Steels', 'Al Alloys', 'Plastics']\n",
    "  ax.set_xticks(range(3))\n",
    "  ax.set_xticklabels(xlabels, rotation = 90, size = 18)\n",
    "  ax.set_yticks(range(3))\n",
    "  ax.set_yticklabels(xlabels, size = 18)\n",
    "  plt.savefig('./figures2D/averageDistanceMatrix.pdf',bbox_inches='tight')\n",
    "drawDistanceMatrix()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8b9d38",
   "metadata": {},
   "source": [
    "## Plots the latent space in 2D with a Convex Hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e964a8-877f-42ac-8dc9-d5baa4b76f0c",
   "metadata": {
    "id": "40e964a8-877f-42ac-8dc9-d5baa4b76f0c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The latent field\n",
    "def plotLatent(saveFileName):\n",
    "    clrs = ['purple', 'green', 'red', 'blue', 'black', 'violet', 'cyan',]\n",
    "    colorcol = dataIdentifier['classID']\n",
    "    ptLabel = dataIdentifier['name']\n",
    "    autoencoder = materialEncoder.vaeNet\n",
    "    z = autoencoder.encoder.z.to('cpu').detach().numpy()\n",
    "    fig, ax = plt.subplots()\n",
    "    #List of meaterials to plot name\n",
    "    matidxs = np.array([13,14,15,48,18,10,9,8,28,20,30,69,27,37,\\\n",
    "                        5,6,73,77,78,85,91,88,75,80,82,83]).astype(int)-2\n",
    "    for i in range(np.max(colorcol)+1): \n",
    "        zMat = np.vstack((z[colorcol == i,0], z[colorcol == i,1])).T\n",
    "        ax.scatter(zMat[:, 0], zMat[:, 1], marker='*', c = 'black', s = 8)#clrs[i]\n",
    "        cent = np.mean(zMat, 0)   \n",
    "        \n",
    "        if(np.shape(zMat)[0]>3):\n",
    "            hull = ConvexHull(zMat)\n",
    "            pts = []\n",
    "            for pt in zMat[hull.simplices]:\n",
    "                pts.append(pt[0].tolist())\n",
    "                pts.append(pt[1].tolist())\n",
    "\n",
    "            pts.sort(key=lambda p: np.arctan2(p[1] - cent[1],\n",
    "                                            p[0] - cent[0]))\n",
    "            pts = pts[0::2]  # Deleting duplicates\n",
    "            pts.insert(len(pts), pts[0])\n",
    "            poly = Polygon(1.1*(np.array(pts)- cent) + cent,\n",
    "                           facecolor= clrs[i], alpha=0.2, edgecolor = 'black') #'black'\n",
    "            poly.set_capstyle('round')\n",
    "            plt.gca().add_patch(poly)\n",
    "        ax.annotate(dataIdentifier['className'][i], (cent[0], cent[1]), size = 15, c = 'red')\n",
    "    for i, txt in enumerate(ptLabel):\n",
    "      if(i in matidxs):\n",
    "        ax.annotate(txt, (z[i,0], z[i,1]), size = 12)\n",
    "\n",
    "    plt.xlabel('$z_0$'.format(0), size = 18)\n",
    "    plt.ylabel('$z_1$'.format(1), size = 18)\n",
    "    minor_ticks = np.arange(-2.5, 2.5, 0.1)\n",
    "    ax.set_xticks(minor_ticks, minor=True)\n",
    "    ax.set_yticks(minor_ticks, minor=True)\n",
    "\n",
    "    plt.grid(which='both')\n",
    "    plt.savefig(saveFileName)\n",
    "\n",
    "    return fig, ax\n",
    "  \n",
    "plotLatent(saveFileName = './figures2D/latent.pdf');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1764604d-3eb5-4218-a8e1-1f837a130049",
   "metadata": {
    "id": "1764604d-3eb5-4218-a8e1-1f837a130049",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plotLatentWithProperty(ltnt1 = 0, ltnt2 = 1):\n",
    "  n = 80\n",
    "  zmin, zmax = -2.5,2.5\n",
    "  X,Y = np.meshgrid(np.linspace(zmin, zmax, n), np.linspace(zmin, zmax, n))\n",
    "  Z = torch.zeros((n**2, vaeSettings['encoder']['latentDim']))\n",
    "  Z[:,ltnt1], Z[:,ltnt2] = to_torch(X.reshape(-1)), to_torch(Y.reshape(-1))\n",
    "\n",
    "  vae = materialEncoder.vaeNet\n",
    "  trainData_z_np = to_np(vae.encoder.z)\n",
    "  decoded = vae.decoder(Z)\n",
    "\n",
    "  #-------------------------------------------#\n",
    "  #props = ['youngsModulus','costPerKg','massDensity','yieldStrength']\n",
    "  for p in props:\n",
    "    idx = materialEncoder.dataInfo[p]['idx']\n",
    "    scaleMax = materialEncoder.dataInfo[p]['scaleMax']\n",
    "    scaleMin = materialEncoder.dataInfo[p]['scaleMin']\n",
    "\n",
    "    matPropVal = 10.**(scaleMin + decoded[:,idx]*(scaleMax - scaleMin))\n",
    "\n",
    "    fig, ax = plotLatent(saveFileName = './figures2D/swrksLatent.pdf')\n",
    "    surf = ax.contourf(X, Y, np.log10(to_np(matPropVal).reshape((n,n))), levels = 20, cmap='coolwarm', alpha = 0.7)\n",
    "    plt.clabel(surf, inline=False, fontsize=12, fmt ='%0.2F', colors = 'red')\n",
    "    ax.set_xlabel('$z_0$')\n",
    "    ax.set_ylabel('$z_1$')\n",
    "    ax.set_title(p)\n",
    "    cbar = plt.colorbar(surf)\n",
    "    cbar.set_label('log10({:s})'.format(str(p)))\n",
    "    plt.savefig('./figures2D/{:s}_latentField.pdf'.format(p), dpi=200, bbox_inches='tight')\n",
    "\n",
    "  #-------------------------------------------#\n",
    "  \n",
    "plotLatentWithProperty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c425e398-37d8-4eaa-9f79-1ae4746fb1dd",
   "metadata": {
    "id": "c425e398-37d8-4eaa-9f79-1ae4746fb1dd"
   },
   "outputs": [],
   "source": [
    "def plotTrueAndReconstructedDistribution():\n",
    "\n",
    "  vae = materialEncoder.vaeNet\n",
    "  trainData_z_np = to_np(vae.encoder.z)\n",
    "  decodedVals = vae.decoder(vae.encoder.z)\n",
    "  \n",
    "  bw = 0.405\n",
    "  fig, ax = plt.subplots(1,2)\n",
    "  #-------------------------------------------#\n",
    "  props = ['youngsModulus','costPerKg','massDensity','yieldStrength']\n",
    "  props_red = ['youngsModulus','yieldStrength']\n",
    "  for ctr, p in enumerate(props_red):\n",
    "    idx = materialEncoder.dataInfo[p]['idx']\n",
    "    scaleMax = materialEncoder.dataInfo[p]['scaleMax']\n",
    "    scaleMin = materialEncoder.dataInfo[p]['scaleMin']\n",
    "\n",
    "    matVal_decoded = 10.**(scaleMin + decodedVals[:,idx]*(scaleMax - scaleMin))\n",
    "    matVal_data = 10.**(scaleMin + trainingData[:,idx]*(scaleMax - scaleMin))\n",
    "\n",
    "    #sns.set_style('white')\n",
    "    plt.subplot(1,2,ctr+1)\n",
    "    f = sns.kdeplot(to_np(matVal_decoded), bw_adjust=bw, fill = True, alpha = 0.1, label='decoded')\n",
    "    f = sns.kdeplot(to_np(matVal_data), bw_adjust=bw,  fill = True, alpha = 0.1, linestyle=\"--\", label='actual')\n",
    "    f.set(xlabel = p, ylabel = 'frequency',yticklabels=[])\n",
    "    plt.legend()\n",
    "    plt.axis('auto')\n",
    "    plt.title(p)\n",
    "  \n",
    "  plt.savefig('./figures2D/trueAndReconstructedDistribution.pdf'.format(p), dpi=200, bbox_inches='tight')\n",
    "\n",
    "plotTrueAndReconstructedDistribution()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36acaf6-facb-45d7-84f9-4abc01d4b6e8",
   "metadata": {
    "id": "c36acaf6-facb-45d7-84f9-4abc01d4b6e8"
   },
   "outputs": [],
   "source": [
    "def plotLatentPropertyWithGradients(ltnt1 = 0, ltnt2 = 1):\n",
    "  n = 40\n",
    "  zmin, zmax = -2.5,2.5\n",
    "  X,Y = np.meshgrid(np.linspace(zmin, zmax, n), np.linspace(zmin, zmax, n))\n",
    "  Z = torch.zeros((n**2, vaeSettings['encoder']['latentDim']))\n",
    "  Z[:,ltnt1], Z[:,ltnt2] = to_torch(X.reshape(-1)), to_torch(Y.reshape(-1))\n",
    "  Z = torch.tensor(Z, requires_grad = True)\n",
    "  vae = materialEncoder.vaeNet\n",
    "  decodedVals = vae.decoder(Z)\n",
    "\n",
    "\n",
    "\n",
    "  fig, ax = plt.subplots(1,1)\n",
    "  #-------------------------------------------#\n",
    "  props = ['youngsModulus','costPerKg','massDensity','yieldStrength']\n",
    "  props_red = ['yieldStrength']\n",
    "  for ctr, p in enumerate(props_red):\n",
    "    idx = materialEncoder.dataInfo[p]['idx']\n",
    "    scaleMax = materialEncoder.dataInfo[p]['scaleMax']\n",
    "    scaleMin = materialEncoder.dataInfo[p]['scaleMin']\n",
    "\n",
    "    matVal_decoded = 10.**(scaleMin + decodedVals[:,idx]*(scaleMax - scaleMin))\n",
    "\n",
    "    dE_dz = to_np(torch.autograd.grad(matVal_decoded, Z, grad_outputs = torch.ones(Z.shape[0]), create_graph = True)[0])\n",
    "    U = dE_dz[:,0] / (1e-4+np.sqrt(dE_dz[:,0]**2 + dE_dz[:,1]**2))\n",
    "    V = dE_dz[:,1] / (1e-4+np.sqrt(dE_dz[:,0]**2 + dE_dz[:,1]**2))\n",
    "    plt.subplot(1,1,ctr+1)\n",
    "    surf = plt.contourf(X, Y, np.log10(to_np(matVal_decoded).reshape((n,n))), levels = 100, cmap='coolwarm', alpha = 0.7)\n",
    "    plt.quiver(X,Y,U,V, headwidth = 0, headlength = 0,headaxislength = 0, color = 'black')\n",
    "#     plt.clabel(surf, inline=False, fontsize=12, fmt ='%0.2F', colors = 'black')\n",
    "    plt.title(p)\n",
    "    plt.xlabel('$z_0$')\n",
    "    plt.ylabel('$z_1$')\n",
    "    cbar = plt.colorbar(surf)\n",
    "#     cbar.set_label('$log_{10}$({:s})'.format(p))\n",
    "  \n",
    "  plt.savefig('./figures2D/latentSpaceGradient.pdf'.format(p), dpi=200, bbox_inches='tight')\n",
    "  \n",
    "plotLatentPropertyWithGradients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384ac652-0015-456b-b511-e0e4aafdaf96",
   "metadata": {
    "id": "384ac652-0015-456b-b511-e0e4aafdaf96"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
